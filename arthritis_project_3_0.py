# -*- coding: utf-8 -*-
"""Arthritis_project 3.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BUEzf7DQKly2Ru9cKlvVRp32DODeyHoF
"""

import numpy as np
import pandas as pd

data = pd.read_csv("data.csv")

data['GENDER'].replace(2, 0, inplace = True)
data[:20]

data['EDUCATION'].replace(4, 3, inplace = True)
data['EDUCATION'].replace(5, 3, inplace = True)
data['EDUCATION'].replace(6, 3, inplace = True)

data['STATUS'].replace(4, 0, inplace = True)
data['STATUS'].replace(3, 0, inplace = True)
data['STATUS'].replace(1, 0, inplace = True)
data['STATUS'].replace(2, 1, inplace = True)

data['Q2'].replace(2, 0, inplace = True)

data['Ad'].replace(1, 0, inplace = True)
data['Ad'].replace(2, 0, inplace = True)
data['Ad'].replace(3, 0, inplace = True)
data['Ad'].replace(4, 0, inplace = True)
data['Ad'].replace(5, 0, inplace = True)
data['Ad'].replace(6, 1, inplace = True)
data['Ad'].replace(7, 1, inplace = True)
data['Ad'].replace(8, 1, inplace = True)

data[:50]

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

data.info()

X = data.drop(["Ad"], axis=1)
y = data["Ad"]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

X_train.value_counts()

X_train.shape, X_test.shape

sns.countplot(x=y_train, data=data, palette='hls')
plt.show()

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(sampling_strategy="not majority")
X_res, y_res = ros.fit_resample(X_train,y_train)

ax = y_res.value_counts().plot.pie(autopct="%.2f")
_= ax.set_title("Over-sampling")

sns.countplot(x=y_res, data=data, palette='hls')
plt.show()

from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve, accuracy_score
from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
from sklearn.model_selection import LeaveOneOut
from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import absolute
from numpy import sqrt
import scipy.stats

MLA = []
#GLM
MLA.append(("Logistic Regression", linear_model.LogisticRegressionCV()))
MLA.append(("Ridge Classifier", linear_model. RidgeClassifierCV()))
#Ensemble Methods
MLA.append(("Ada Boost", ensemble.AdaBoostClassifier()))
MLA.append(("Bagging", ensemble.BaggingClassifier()))
MLA.append(("Gradient Boosting", ensemble.GradientBoostingClassifier()))
MLA.append(("Random Forest", ensemble.RandomForestClassifier()))
#Gaussian Processes
MLA.append(("Gaussian", gaussian_process.GaussianProcessClassifier()))
#SVM
MLA.append(("Support Vector Machine", svm.SVC(probability=True)))
MLA.append(("Linear SVC", svm.LinearSVC()))
#Trees
MLA.append(("Decission Tree", tree.DecisionTreeClassifier()))
#Naive Bayes
MLA.append(("Bernoulli NB", naive_bayes.BernoulliNB()))
MLA.append(("Gaussian NB", naive_bayes.GaussianNB()))
#Nearest Neighbor
MLA.append(("KNN", neighbors.KNeighborsClassifier()))

MLA

confidence = 0.95
z_value = scipy.stats.norm.ppf((1 + confidence) / 2.0)
print(z_value)

MLA_columns = []
MLA_compare = pd.DataFrame(columns = MLA_columns)

row_index = 0
kfold = KFold(n_splits = 5, random_state=2, shuffle=True)
for name, model in MLA:

  predicted = model.fit(X_res, y_res).predict(X_test)
  fp, tp, th = roc_curve(y_test, predicted)
  acc_test = model.score(X_test, y_test)
  ci_length = z_value * np.sqrt((acc_test * (1 - acc_test)) / y_test.shape[0])
  MLA_compare.loc[row_index,'MLA used'] = name
  MLA_compare.loc[row_index, 'K-fold Train Accuracy'] = cross_val_score(model, X_res, y_res, cv=kfold, scoring='accuracy').mean()
  MLA_compare.loc[row_index, 'K-fold Test Accuracy'] = cross_val_score(model, X_test, y_test, cv=kfold, scoring='accuracy').mean()
  MLA_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted)
  MLA_compare.loc[row_index, 'Precission'] = precision_score(y_test, predicted)
  MLA_compare.loc[row_index, 'Recall'] = recall_score(y_test, predicted)
  MLA_compare.loc[row_index, 'F1 Score'] = 2 * (precision_score(y_test, predicted)* recall_score(y_test, predicted)) / (precision_score(y_test, predicted) + recall_score(y_test, predicted))
  MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)
  MLA_compare.loc[row_index, 'LL'] = acc_test - ci_length
  MLA_compare.loc[row_index, 'UL'] = acc_test + ci_length
  row_index+=1

MLA_compare.sort_values(by = ['AUC'], ascending = False, inplace = True)
MLA_compare

results_df = pd.DataFrame()

X_test_df = pd.DataFrame(X_test)

# Save X_test DataFrame to an Excel file
X_test_df.to_csv('X_test.csv', index=False)

# Create a DataFrame from y_test
y_test_df = pd.DataFrame(y_test)

# Save y_test DataFrame to an Excel file
y_test_df.to_csv('y_test.csv', index=False)

results_df = pd.DataFrame()

for name, model in MLA:


    # Make predictions using the model
    predicted = model.fit(X_res, y_res).predict(X_test)

    # Create a temporary DataFrame for the current model's predicted results
    temp_df = pd.DataFrame({name: predicted})

    # Append the temporary DataFrame to the results DataFrame
    results_df = pd.concat([results_df, temp_df], axis=1)

# Export the results DataFrame to an Excel file
results_df.to_csv('predicted_results.csv', index=False)

! cat predictions.csv

!pip install mlxtend
import joblib
import sys
sys.modules['sklearn.externals.joblib'] = joblib
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs
from sklearn import metrics

from sklearn.model_selection import StratifiedKFold

# forward selection
cv = StratifiedKFold(n_splits=5, random_state=2, shuffle=True)
accuracy_df = pd.DataFrame({"feature count":[], "accuracy":[], "score function":[]})
for i in range(1, len(data.columns) - 1):
  sfs = SFS(LogisticRegression(),
            k_features = i,
            forward = True,
            scoring = "accuracy",
            cv = cv)

  X_train_selected = sfs.fit_transform(X_res, y_res)
  reg = LogisticRegression()
  reg.fit(X_train_selected, y_res)
  y_pred = reg.predict(X_test[list(sfs.k_feature_names_)])
  sfs_accuracy = metrics.accuracy_score(y_test, y_pred)

  new_record = {"feature count": round(i), "accuracy": round(sfs_accuracy, 3), "score function": "forward selection"}
  accuracy_df = accuracy_df.append(new_record, ignore_index = True)

print(accuracy_df)
plt.figure(figsize = (10,10))
sns.lineplot(data = accuracy_df, x = 'feature count', y = 'accuracy', hue = 'score function', palette = 'GnBu')

from sklearn.feature_selection import RFE

#Feature Selection with Recursive feature Elimination
rfe = RFE(LogisticRegression(), n_features_to_select=7)
rfe.fit(X_res, y_res)

Columns = X_train.columns
RFE_support = rfe.support_
RFE_ranking = rfe.ranking_

dataset = pd.DataFrame({'Columns': Columns, 'RFE_support': RFE_support, 'RFE_ranking': RFE_ranking}, columns=['Columns', 'RFE_support', 'RFE_ranking'])
dataset

df = dataset[(dataset["RFE_support"] == True) & (dataset["RFE_ranking"] == 1)]
filtered_features = df['Columns']
filtered_features

filtered_train_x = X_res[filtered_features]
filtered_test_x = X_test[filtered_features]

MLA_columns = []
MLA_compare = pd.DataFrame(columns = MLA_columns)

row_index = 0
kfold = KFold(n_splits = 5, random_state=2, shuffle=True)
for name, model in MLA:

  predicted = model.fit(filtered_train_x, y_res).predict(filtered_test_x)
  fp, tp, th = roc_curve(y_test, predicted)
  acc_test = model.score(filtered_test_x, y_test)
  MLA_compare.loc[row_index,'MLA used'] = name
  MLA_compare.loc[row_index, 'K-fold Train Accuracy'] = cross_val_score(model, filtered_train_x, y_res, cv=kfold, scoring='accuracy').mean()
  MLA_compare.loc[row_index, 'K-fold Test Accuracy'] = cross_val_score(model, filtered_test_x, y_test, cv=kfold, scoring='accuracy').mean()
  MLA_compare.loc[row_index, 'Accuracy'] = accuracy_score(y_test, predicted)
  MLA_compare.loc[row_index, 'Precission'] = precision_score(y_test, predicted)
  MLA_compare.loc[row_index, 'Recall'] = recall_score(y_test, predicted)
  MLA_compare.loc[row_index, 'F1 Score'] = 2 * (precision_score(y_test, predicted)* recall_score(y_test, predicted)) / (precision_score(y_test, predicted) + recall_score(y_test, predicted))
  MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)
  MLA_compare.loc[row_index, 'LL'] = acc_test - ci_length
  MLA_compare.loc[row_index, 'UL'] = acc_test + ci_length
  row_index+=1

MLA_compare.sort_values(by = ['AUC'], ascending = False, inplace = True)
MLA_compare

X_test_filtered_df = pd.DataFrame(filtered_test_x)

# Save X_test DataFrame to an Excel file
X_test_filtered_df.to_csv('X_test_filtered.csv', index=False)

# Create a DataFrame from y_test
y_test_df_filtered = pd.DataFrame(y_test)

# Save y_test DataFrame to an Excel file
y_test_df_filtered.to_csv('y_test.csv', index=False)

results_df_filtered = pd.DataFrame()

for name, model in MLA:


    # Make predictions using the model
    predicted = model.fit(filtered_train_x, y_res).predict(filtered_test_x)

    # Create a temporary DataFrame for the current model's predicted results
    temp_df = pd.DataFrame({name: predicted})

    # Append the temporary DataFrame to the results DataFrame
    results_df_filtered = pd.concat([results_df_filtered, temp_df], axis=1)

# Export the results DataFrame to an Excel file
results_df_filtered.to_csv('predicted_results_filtered.csv', index=False)

!pip install shap
import shap
shap.initjs()

#SHAP Analysis of gradient boost model
GB_model = ensemble.GradientBoostingClassifier()
GB_model.fit(filtered_train_x, y_res)

explainer = shap.KernelExplainer(GB_model.predict, filtered_test_x)

shap_values = explainer.shap_values(filtered_test_x)

shap.summary_plot(shap_values, filtered_test_x)

import time
from sklearn.gaussian_process.kernels import WhiteKernel, DotProduct

kernel = DotProduct() + WhiteKernel()

gau_model = gaussian_process.GaussianProcessClassifier(kernel)

gau_model.fit(filtered_train_x, y_res)
#y_pred = gau_model.predict(filtered_test_x)

explainer = shap.KernelExplainer(gau_model.predict, filtered_test_x)

shap_values = explainer.shap_values(filtered_test_x)

shap.summary_plot(shap_values, filtered_test_x)